{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Please install tensorflow_hub and top2vec before running the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment the below 2 lines of code to download the required libraries.\n",
        "# ! pip install top2vec\n",
        "# ! pip install --upgrade tensorflow-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b8wBdegtDELD"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from top2vec import Top2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
        "model = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "DwijX1T9DjVM",
        "outputId": "9809d1c8-9f9e-43e0-ce9d-a479de40620c"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv('Train.csv')\n",
        "df2 = pd.read_csv('Test.csv')\n",
        "\n",
        "# Concatenate the dataframes\n",
        "df = pd.concat([df1, df2])\n",
        "\n",
        "# Print the shape of the concatenated dataframe\n",
        "print(df.shape)\n",
        "\n",
        "# Print the first 5 rows of the concatenated dataframe\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML3M1iZODysI"
      },
      "outputs": [],
      "source": [
        "docs = list(df.loc[:, \"ABSTRACT\"].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs = [d.replace(\"See \", \"\") for d in docs]\n",
        "docs = [re.sub(r\"\\([^()]*\\)\", \"\",  d).replace(\" .\", \".\") for d in docs]\n",
        "\n",
        "docs[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tzVBxiTiD947",
        "outputId": "1c02cd0e-a59f-40cb-eb25-70db8b508bc0"
      },
      "outputs": [],
      "source": [
        "semanticmodel = Top2Vec(docs, \n",
        "                        embedding_model = model, # Embedding model: See [1,2] for supported models\n",
        "                        min_count = 20,              # Ignore words less frequent than this value\n",
        "                        speed=\"deep-learn\",\n",
        "                        ngram_vocab=True) #speed=\"deep-learn\", workers=8, embedding_model=model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(semanticmodel.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bigrams = []\n",
        "for word in semanticmodel.vocab:\n",
        "    if len(word.split()) == 2:\n",
        "        bigrams.append(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(bigrams))\n",
        "bigrams[0:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yyNuP2aKEBt7",
        "outputId": "1f208606-7d94-4f74-e8d6-7c251d646631"
      },
      "outputs": [],
      "source": [
        "topic_sizes, topic_nums = semanticmodel.get_topic_sizes()\n",
        "\n",
        "print(topic_nums)\n",
        "print(topic_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDNuXenjEIlA"
      },
      "outputs": [],
      "source": [
        "topic_words, word_scores, topic_nums = semanticmodel.get_topics(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for words, scores, num in zip(topic_words, word_scores, topic_nums):\n",
        "    print(num)\n",
        "    print(f\"Words: {words}\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2043
        },
        "id": "wY6ulsABEKtB",
        "outputId": "1c919364-a50a-49c3-a31c-db7330697637"
      },
      "outputs": [],
      "source": [
        "for topic in topic_nums:\n",
        "    semanticmodel.generate_topic_wordcloud(topic) # , background_color=\"black\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1SHhSQCLEMKb",
        "outputId": "9d62f5bd-533c-42c7-add3-113782d03f96"
      },
      "outputs": [],
      "source": [
        "documents, document_scores, document_ids = semanticmodel.search_documents_by_topic(topic_num=0, num_docs=5)\n",
        "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
        "    print(f\"Document: {doc_id}, Score: {score}\")\n",
        "    print(\"-----------\")\n",
        "    print(doc)\n",
        "    print(\"-----------\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DlQzIZlOESXj",
        "outputId": "6cb40f1a-c4bd-45ba-8134-495ba061710e"
      },
      "outputs": [],
      "source": [
        "documents, document_scores, document_ids = semanticmodel.search_documents_by_keywords(keywords=[\"svm\", \"bayesian\"], num_docs=5)\n",
        "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
        "    print(f\"Document: {doc_id}, Score: {score}\")\n",
        "    print(\"-----------\")\n",
        "    print(doc)\n",
        "    print(\"-----------\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EMsVTLYAES8e",
        "outputId": "776c9214-b0e2-4bbb-d5cd-14a403edb9a4"
      },
      "outputs": [],
      "source": [
        "words, word_scores = semanticmodel.similar_words(keywords=[\"face recognition\"], keywords_neg=[], num_words=20)\n",
        "for word, score in zip(words, word_scores):\n",
        "    print(f\"{word} {score}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References:\n",
        "1. [Tensorflow_hub_Universal Sentence Encoder](https://www.tensorflow.org/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder)\n",
        "2. [top2vec](https://pypi.org/project/top2vec/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
